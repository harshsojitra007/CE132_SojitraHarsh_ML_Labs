{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9YIxTzp9mcekBAkXgjATS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshsojitra007/CE132_SojitraHarsh_ML_Labs/blob/main/ML_Lab_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "btWgL31eJgGB",
        "outputId": "26ac2c7b-a58e-4337-d281-34e9c419fede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-140edc46f791>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  features_train = torch.tensor(features_train, requires_grad=True)\n",
            "<ipython-input-3-140edc46f791>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  targets_train = torch.tensor(targets_train)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM30lEQVR4nO3dX4hc9RnG8eeJNiC2SqJ2WUzQtEShlGhLlGpFU2JDmpvYC4tBa0rFFaxgoRcVe1FBClpsS28sbFWS1tRSiKuh1LZpKNqCht1IqvljEhsS3SUmFZGmKLbRtxd70q5x58xm5pw5s/t+PzDMzHnnzLwc8uR3/szszxEhAHPfvKYbANAbhB1IgrADSRB2IAnCDiRxZi8/zDan/oGaRYSnW97VyG57te19tl+1fU837wWgXu70OrvtMyTtl/RlSeOSRiWti4g9JeswsgM1q2Nkv1LSqxFxMCL+LenXktZ28X4AatRN2C+U9PqU5+PFsg+xPWR7zPZYF58FoEu1n6CLiGFJwxK78UCTuhnZJyQtnvJ8UbEMQB/qJuyjkpbaXmJ7vqSbJG2ppi0AVet4Nz4iTti+S9IfJJ0h6bGI2F1ZZwAq1fGlt44+jGN2oHa1fKkGwOxB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIdT9kM9LuVK1e2rG3atKl03euuu660vm/fvo56alJXYbd9SNJxSe9LOhERy6toCkD1qhjZvxQRb1bwPgBqxDE7kES3YQ9Jf7S9w/bQdC+wPWR7zPZYl58FoAvd7sZfExETtj8paavtVyLiuakviIhhScOSZDu6/DwAHepqZI+IieL+mKQRSVdW0RSA6nUcdttn2/7EyceSVknaVVVjAKrVzW78gKQR2yff51cR8ftKuqrBtddeW1o/77zzSusjIyNVtoMeuOKKK1rWRkdHe9hJf+g47BFxUNJlFfYCoEZcegOSIOxAEoQdSIKwA0kQdiCJND9xXbFiRWl96dKlpXUuvfWfefPKx6olS5a0rF100UWl6xaXlOcURnYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNdfZbb721tP7888/3qBNUZXBwsLR+++23t6w9/vjjpeu+8sorHfXUzxjZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJNNfZ2/32GbPPI4880vG6Bw4cqLCT2YEEAEkQdiAJwg4kQdiBJAg7kARhB5Ig7EASc+Y6+7Jly0rrAwMDPeoEvXLuued2vO7WrVsr7GR2aDuy237M9jHbu6YsW2h7q+0Dxf2CetsE0K2Z7MZvkLT6lGX3SNoWEUslbSueA+hjbcMeEc9JeuuUxWslbSweb5R0Q7VtAahap8fsAxFxpHj8hqSWB8S2hyQNdfg5ACrS9Qm6iAjbUVIfljQsSWWvA1CvTi+9HbU9KEnF/bHqWgJQh07DvkXS+uLxeklPV9MOgLq03Y23/YSkFZLOtz0u6fuSHpD0G9u3STos6Wt1NjkTa9asKa2fddZZPeoEVWn33Yiy+dfbmZiY6Hjd2apt2CNiXYvSyop7AVAjvi4LJEHYgSQIO5AEYQeSIOxAEnPmJ66XXnppV+vv3r27ok5QlYceeqi03u7S3P79+1vWjh8/3lFPsxkjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kMWeus3drdHS06RZmpXPOOae0vnr1qX+r9P9uueWW0nVXrVrVUU8n3X///S1rb7/9dlfvPRsxsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAElxnLyxcuLCxz77ssstK67ZL69dff33L2qJFi0rXnT9/fmn95ptvLq3Pm1c+Xrz77rsta9u3by9d97333iutn3lm+T/fHTt2lNazYWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQcEb37MLu2D3v44YdL63fccUdpvd3vm1977bXTbWnGli1bVlpvd539xIkTLWvvvPNO6bp79uwprbe7Fj42NlZaf/bZZ1vWjh49Wrru+Ph4aX3BggWl9XbfIZirImLafzBtR3bbj9k+ZnvXlGX32Z6wvbO4lU+ODqBxM9mN3yBpuj838pOIuLy4/a7atgBUrW3YI+I5SW/1oBcANermBN1dtl8qdvNbHjzZHrI9Zrv84A5ArToN+88kfVrS5ZKOSPpRqxdGxHBELI+I5R1+FoAKdBT2iDgaEe9HxAeSfi7pymrbAlC1jsJue3DK069K2tXqtQD6Q9vfs9t+QtIKSefbHpf0fUkrbF8uKSQdklR+EbsH7rzzztL64cOHS+tXX311le2clnbX8J966qnS+t69e1vWXnjhhU5a6omhoaHS+gUXXFBaP3jwYJXtzHltwx4R66ZZ/GgNvQCoEV+XBZIg7EAShB1IgrADSRB2IIk0f0r6wQcfbLoFnGLlypVdrb958+aKOsmBkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkkhznR1zz8jISNMtzCqM7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEv2dH37JdWr/kkktK6/08XXUT2o7sthfb/rPtPbZ32767WL7Q9lbbB4r7BfW3C6BTM9mNPyHpOxHxGUlfkPQt25+RdI+kbRGxVNK24jmAPtU27BFxJCJeLB4fl7RX0oWS1kraWLxso6QbauoRQAVO65jd9sWSPidpu6SBiDhSlN6QNNBinSFJQ130CKACMz4bb/vjkjZL+nZE/HNqLSJCUky3XkQMR8TyiFjeVacAujKjsNv+mCaDvikiniwWH7U9WNQHJR2rp0UAVZjJ2XhLelTS3oj48ZTSFknri8frJT1dfXvILCJKb/PmzSu94cNmcsz+RUlfl/Sy7Z3FsnslPSDpN7Zvk3RY0tdq6RBAJdqGPSL+KqnVtxtWVtsOgLqwrwMkQdiBJAg7kARhB5Ig7EAS/MQVs9ZVV11VWt+wYUNvGpklGNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmus6NvtftT0jg9jOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATX2dGYZ555prR+44039qiTHBjZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T5C+zFkn4haUBSSBqOiJ/avk/S7ZL+Ubz03oj4XZv3Kv8wAF2LiGn/EMBMwj4oaTAiXrT9CUk7JN2gyfnY/xURD820CcIO1K9V2GcyP/sRSUeKx8dt75V0YbXtAajbaR2z275Y0uckbS8W3WX7JduP2V7QYp0h22O2x7prFUA32u7G/++F9sclPSvpBxHxpO0BSW9q8jj+fk3u6n+zzXuwGw/UrONjdkmy/TFJv5X0h4j48TT1iyX9NiI+2+Z9CDtQs1Zhb7sb78k/8fmopL1Tg16cuDvpq5J2ddskgPrM5Gz8NZL+IullSR8Ui++VtE7S5ZrcjT8k6Y7iZF7ZezGyAzXraje+KoQdqF/Hu/EA5gbCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEr2esvlNSYenPD+/WNaP+rW3fu1LordOVdnbRa0KPf09+0c+3B6LiOWNNVCiX3vr174keutUr3pjNx5IgrADSTQd9uGGP79Mv/bWr31J9NapnvTW6DE7gN5pemQH0COEHUiikbDbXm17n+1Xbd/TRA+t2D5k+2XbO5uen66YQ++Y7V1Tli20vdX2geJ+2jn2GurtPtsTxbbbaXtNQ70ttv1n23ts77Z9d7G80W1X0ldPtlvPj9ltnyFpv6QvSxqXNCppXUTs6WkjLdg+JGl5RDT+BQzb10r6l6RfnJxay/YPJb0VEQ8U/1EuiIjv9klv9+k0p/GuqbdW04x/Qw1uuyqnP+9EEyP7lZJejYiDEfFvSb+WtLaBPvpeRDwn6a1TFq+VtLF4vFGT/1h6rkVvfSEijkTEi8Xj45JOTjPe6LYr6asnmgj7hZJen/J8XP0133tI+qPtHbaHmm5mGgNTptl6Q9JAk81Mo+003r10yjTjfbPtOpn+vFucoPuoayLi85K+Iulbxe5qX4rJY7B+unb6M0mf1uQcgEck/ajJZoppxjdL+nZE/HNqrcltN01fPdluTYR9QtLiKc8XFcv6QkRMFPfHJI1o8rCjnxw9OYNucX+s4X7+JyKORsT7EfGBpJ+rwW1XTDO+WdKmiHiyWNz4tpuur15ttybCPippqe0ltudLuknSlgb6+AjbZxcnTmT7bEmr1H9TUW+RtL54vF7S0w328iH9Mo13q2nG1fC2a3z684jo+U3SGk2ekf+7pO810UOLvj4l6W/FbXfTvUl6QpO7df/R5LmN2ySdJ2mbpAOS/iRpYR/19ktNTu39kiaDNdhQb9dochf9JUk7i9uaprddSV892W58XRZIghN0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEfwHjYfAoH2KvwQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500 Loss: 0.6412 Accuracy: 87.19 %\n",
            "Iteration: 1000 Loss: 0.4602 Accuracy: 89.58 %\n",
            "Iteration: 1500 Loss: 0.3762 Accuracy: 90.56 %\n",
            "Iteration: 2000 Loss: 0.2290 Accuracy: 91.14 %\n",
            "Iteration: 2500 Loss: 0.3596 Accuracy: 91.81 %\n",
            "Iteration: 3000 Loss: 0.1841 Accuracy: 92.13 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load MNIST dataset from torchvision.datasets\n",
        "mnist = MNIST(root='data/', train=True, download=True)\n",
        "\n",
        "# Convert features to float32 and targets to long\n",
        "features_train = mnist.data.float()\n",
        "targets_train = mnist.targets.long()\n",
        "\n",
        "# Normalize features from [0, 255] to [0, 1]\n",
        "features_train /= 255\n",
        "\n",
        "# Flatten features to 1-D vector of 784 features\n",
        "features_train = features_train.view(-1, 784)\n",
        "\n",
        "n_iters = 5000\n",
        "batch_size = 100\n",
        "num_epochs = n_iters // (len(features_train) // batch_size)\n",
        "\n",
        "# Create PyTorch tensor and variable for features and targets for training set\n",
        "train_set = TensorDataset(features_train, targets_train)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "features_train = torch.tensor(features_train, requires_grad=True)\n",
        "targets_train = torch.tensor(targets_train)\n",
        "\n",
        "mnist_test = MNIST(root='data/', train=False, download=True)\n",
        "features_test = mnist_test.data.float()\n",
        "targets_test = mnist_test.targets.long()\n",
        "features_test /= 255\n",
        "features_test = features_test.view(-1, 784)\n",
        "\n",
        "# Create PyTorch tensor for features and targets for test set\n",
        "test_set = TensorDataset(features_test, targets_test)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Visualize one of the images in the training set\n",
        "\n",
        "plt.imshow(mnist.data[2], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# instantiate ANN\n",
        "input_dim = 28*28\n",
        "\n",
        "# this defines no. of hidden layers\n",
        "# hidden_dim = 150  \n",
        "hidden_dim = 200\n",
        "output_dim = 10\n",
        "\n",
        "# Create ANN\n",
        "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# SGD Optimizer\n",
        "learning_rate = 0.02\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Set number of epochs\n",
        "num_epochs = 5\n",
        "count = 0\n",
        "\n",
        "# Define empty lists to store loss, iteration and accuracy values\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Convert input and labels to Variables\n",
        "        train = Variable(images.view(-1, 28*28))\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward propagation\n",
        "        outputs = model(train)\n",
        "\n",
        "        # Calculate softmax and cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Calculating gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Count iterations\n",
        "        count += 1\n",
        "\n",
        "        # Calculate accuracy every 50 iterations\n",
        "        if count % 50 == 0:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in test_loader:\n",
        "                test = Variable(images.view(-1, 28*28))\n",
        "                outputs = model(test)\n",
        "                predicted = torch.max(outputs.data, 1)[1]\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / float(total)\n",
        "\n",
        "            # Store loss and iteration values\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "\n",
        "        # Print loss and accuracy every 500 iterations\n",
        "        if count % 500 == 0:\n",
        "            print('Iteration: {} Loss: {:.4f} Accuracy: {:.2f} %'.\n",
        "                  format(count, loss.data, accuracy))\n"
      ]
    }
  ]
}